{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Proyecto Churn ‚Äî Telecom X (LATAM)\n",
        "\n",
        "### Notebook: An√°lisis, limpieza y preparaci√≥n de datos para modelado\n",
        "\n",
        "Este notebook toma como entrada el archivo `TelecomX_Data.json`, realiza una exploraci√≥n, limpieza y preparaci√≥n de los datos (feature engineering y exportaci√≥n). El resultado es un dataset limpio listo para que el equipo de Ciencia de Datos pueda construir modelos predictivos de churn.\n",
        "\n",
        "**Instrucciones:**\n",
        "- Ejecuta todas las celdas en orden.\n",
        "- El notebook genera un archivo `TelecomX_Data_clean.csv` con los datos limpios.\n",
        "\n",
        "Desarrollado como soluci√≥n descargable para el cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Librer√≠as necesarias\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "sns.set(style='whitegrid', palette='pastel', font_scale=1.05)\n",
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "print('Librer√≠as cargadas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cargar los datos\n",
        "\n",
        "Se asume que el archivo `TelecomX_Data.json` est√° en el mismo directorio que este notebook o en `/mnt/data/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intentamos localizar el archivo en rutas comunes\n",
        "candidates = [\n",
        "    'TelecomX_Data.json',\n",
        "    '/mnt/data/TelecomX_Data.json',\n",
        "    './data/TelecomX_Data.json'\n",
        "]\n",
        "data_path = None\n",
        "for p in candidates:\n",
        "    if Path(p).exists():\n",
        "        data_path = Path(p)\n",
        "        break\n",
        "\n",
        "if data_path is None:\n",
        "    raise FileNotFoundError('No se encontr√≥ TelecomX_Data.json. Coloca el archivo en el mismo directorio que el notebook o en /mnt/data/')\n",
        "else:\n",
        "    print(f'Archivo encontrado en: {data_path}')\n",
        "\n",
        "# Cargar JSON a DataFrame (maneja formatos de lista de registros o l√≠nea por l√≠nea)\n",
        "try:\n",
        "    df = pd.read_json(data_path)\n",
        "except ValueError:\n",
        "    # fallback a read_json orient='records' o lines=True\n",
        "    try:\n",
        "        df = pd.read_json(data_path, lines=True)\n",
        "    except Exception as e:\n",
        "        raise\n",
        "\n",
        "print('Datos cargados en DataFrame con forma:', df.shape)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Inspecci√≥n r√°pida\n",
        "Revisamos tipos, valores nulos y descripci√≥n estad√≠stica para entender la estructura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Tipos de datos:')\n",
        "display(df.dtypes)\n",
        "\n",
        "print('\\nResumen de valores nulos por columna:')\n",
        "display(df.isna().sum())\n",
        "\n",
        "print('\\nDescripci√≥n estad√≠stica (num√©rica):')\n",
        "display(df.describe(include=[np.number]))\n",
        "\n",
        "print('\\nDescripci√≥n (objetos/categor√≠as):')\n",
        "display(df.describe(include=['object', 'category']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Objetivo: identificar la variable de churn\n",
        "\n",
        "Buscamos columnas que indiquen abandono del cliente (por ejemplo `churn`, `is_churn`, `cancelled`, `status`, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscar columnas que puedan indicar churn\n",
        "possible_churn_cols = [c for c in df.columns if 'churn' in c.lower() or 'cancel' in c.lower() or 'status' in c.lower() or 'aband' in c.lower()]\n",
        "print('Columnas candidatas a churn:', possible_churn_cols)\n",
        "display(df[possible_churn_cols].head()) if possible_churn_cols else print('No se detectaron columnas con nombres obvios para churn.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si no existe una columna obvia, habr√° que crear una variable objetivo basada en reglas (por ejemplo, `contract_end` o `days_without_service`). En este notebook seguiremos ambos enfoques: si existe `churn` la usaremos; si no, intentaremos inferirla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos la variable objetivo 'churn' si no existe\n",
        "lower_cols = [c.lower() for c in df.columns]\n",
        "if 'churn' in lower_cols:\n",
        "    churn_col = [c for c in df.columns if c.lower()=='churn'][0]\n",
        "    df['churn'] = df[churn_col].astype(int)\n",
        "    print('Se us√≥ la columna existente:', churn_col)\n",
        "elif possible_churn_cols:\n",
        "    # si hay columnas candidatas, escogemos la primera (solo heur√≠stica)\n",
        "    df['churn'] = df[possible_churn_cols[0]].apply(lambda x: 1 if str(x).lower() in ['yes','y','true','1','si','s','cancelled'] else 0)\n",
        "    print('Se cre√≥ churn a partir de:', possible_churn_cols[0])\n",
        "else:\n",
        "    print('No se detect√≥ columna de churn. Se intentar√° inferir a partir de columnas de estado o de fecha (si existe).')\n",
        "    if 'status' in df.columns:\n",
        "        df['churn'] = df['status'].apply(lambda x: 1 if str(x).lower() in ['inactive','cancelled','suspended','terminated'] else 0)\n",
        "    else:\n",
        "        df['churn'] = 0\n",
        "        print('Se estableci√≥ churn=0 por defecto: revisa manualmente')\n",
        "\n",
        "display(df[['churn']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Limpieza b√°sica\n",
        "- Normalizar nombres de columnas\n",
        "- Tratar valores nulos\n",
        "- Convertir tipos\n",
        "- Detectar y tratar outliers sencillos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar columnas: minusculas y reemplazar espacios\n",
        "df.columns = [c.strip().lower().replace(' ', '_').replace('/', '_') for c in df.columns]\n",
        "print('Columnas normalizadas')\n",
        "display(df.columns)\n",
        "\n",
        "# Mostrar nulos porcentuales\n",
        "nulos = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
        "display(nulos.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estrategia de imputaci√≥n (heur√≠stica) - se aporta como plantilla\n",
        "df_clean = df.copy()\n",
        "num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print('Columnas num√©ricas:', num_cols)\n",
        "print('Columnas categ√≥ricas:', cat_cols)\n",
        "\n",
        "for c in num_cols:\n",
        "    if df_clean[c].isna().sum() > 0:\n",
        "        med = df_clean[c].median()\n",
        "        df_clean[c].fillna(med, inplace=True)\n",
        "\n",
        "for c in cat_cols:\n",
        "    if df_clean[c].isna().sum() > 0:\n",
        "        df_clean[c].fillna('missing', inplace=True)\n",
        "\n",
        "print('Imputaci√≥n realizada. Nulos restantes por columna:')\n",
        "display(df_clean.isna().sum()[df_clean.isna().sum()>0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. An√°lisis exploratorio b√°sico (EDA)\n",
        "Calculamos tasas de churn, visualizamos distribuciones y relaciones entre variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_rate = df_clean['churn'].mean()\n",
        "print(f'Tasa de churn (porcentaje): {churn_rate*100:.2f}%')\n",
        "\n",
        "sns.countplot(x='churn', data=df_clean)\n",
        "plt.title('Distribuci√≥n de churn (0 = activo, 1 = churn)')\n",
        "plt.show()\n",
        "\n",
        "sample_cats = [c for c in cat_cols if c not in ['id', 'customer_id']][:5]\n",
        "for c in sample_cats:\n",
        "    plt.figure()\n",
        "    ct = pd.crosstab(df_clean[c], df_clean['churn'], normalize='index')*100\n",
        "    ct.plot(kind='bar', stacked=True)\n",
        "    plt.title(f'Churn por {c}')\n",
        "    plt.ylabel('Porcentaje por fila')\n",
        "    plt.legend(title='churn')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(num_cols) > 0:\n",
        "    corr = df_clean[num_cols + ['churn']].corr()\n",
        "    plt.figure(figsize=(12,8))\n",
        "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "    plt.title('Mapa de correlaci√≥n (num√©ricas + churn)')\n",
        "    plt.show()\n",
        "else:\n",
        "    print('No hay columnas num√©ricas para calcular correlaci√≥n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Feature engineering r√°pido\n",
        "- Convertir fechas a datetime\n",
        "- Crear variables simples (tenure en meses, totales, promedios)\n",
        "\n",
        "Se muestra una plantilla: adapta seg√∫n las columnas reales del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'signup_date' in df_clean.columns and 'last_active_date' in df_clean.columns:\n",
        "    df_clean['signup_date'] = pd.to_datetime(df_clean['signup_date'], errors='coerce')\n",
        "    df_clean['last_active_date'] = pd.to_datetime(df_clean['last_active_date'], errors='coerce')\n",
        "    df_clean['tenure_days'] = (df_clean['last_active_date'] - df_clean['signup_date']).dt.days\n",
        "    df_clean['tenure_months'] = (df_clean['tenure_days'] / 30).round(1)\n",
        "    print('Se cre√≥ tenure_months')\n",
        "else:\n",
        "    print('No se detectaron columnas de fecha para crear tenure. Revisar manualmente.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Preparar dataset final para modelado\n",
        "- Codificar variables categ√≥ricas (label encoding / one-hot)\n",
        "- Seleccionar features relevantes\n",
        "- Exportar CSV limpio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_model = df_clean.copy()\n",
        "cat_small = [c for c in cat_cols if df_model[c].nunique() <= 10 and c != 'churn']\n",
        "print('Categor√≠as a one-hot:', cat_small)\n",
        "df_model = pd.get_dummies(df_model, columns=cat_small, drop_first=True)\n",
        "df_model['churn'] = df_model['churn'].astype(int)\n",
        "out_path = Path('TelecomX_Data_clean.csv')\n",
        "df_model.to_csv(out_path, index=False)\n",
        "print(f'Dataset limpio guardado en: {out_path} con shape {df_model.shape}')\n",
        "display(df_model.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Recomendaciones y siguientes pasos\n",
        "\n",
        "1. Revisar manualmente la definici√≥n de `churn` si fue inferida por heur√≠stica.\n",
        "2. Realizar an√°lisis de balanceo (SMOTE / undersampling) si la clase churn est√° desbalanceada.\n",
        "3. Avanzar con pipeline de modelado: separaci√≥n train/test, validaci√≥n cruzada y pruebas con modelos (Logistic Regression, Random Forest, XGBoost).\n",
        "4. Documentar transformaciones aplicadas (important√≠simo para producci√≥n y reproducibilidad).\n",
        "\n",
        "Esto entrega al equipo de ciencia de datos un CSV listo para entrenar modelos predictivos.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}